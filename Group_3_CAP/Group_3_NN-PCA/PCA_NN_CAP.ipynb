{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUp2OVqeLBrM"
   },
   "source": [
    "# Importing the librares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0EL8pelBLLt_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M3QQzQrK4JY"
   },
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "7-jNgcCEJRQn"
   },
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('X_trainData_1.csv')\n",
    "#labels=pd.read_csv('Y_trainData_1.csv')\n",
    "dataset = pd.read_csv('X_trainData_column_modified_PCA_CAP.csv')\n",
    "datalabels=pd.read_csv('X_trainData_column_modified_CAP.csv')\n",
    "\n",
    "\n",
    "X_train=dataset.iloc[:,:].values\n",
    "#X_train=dataset.iloc[:,:-1].values\n",
    "y_train=datalabels.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb8TObA8vGuc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "RDM-TheaftrR",
    "outputId": "d6f3a524-a70c-4e28-987f-30c2f447a7f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.07575094e+02 -1.90119808e+01 ...  1.67585513e-01\n",
      "  -1.60297759e-02 -2.52419486e-02]\n",
      " [ 2.00000000e+00  1.12747163e+02 -1.94524891e+01 ...  2.39257476e-01\n",
      "   7.85068934e-02 -3.99865137e-01]\n",
      " [ 3.00000000e+00  9.82537761e+01 -1.91011436e+01 ...  2.95889586e+00\n",
      "  -6.80896853e-01  2.05905530e-01]\n",
      " ...\n",
      " [ 1.33700000e+03  1.12481339e+02  4.59098368e+01 ... -7.63968245e-02\n",
      "  -3.91108815e-01 -3.47513066e-01]\n",
      " [ 1.33800000e+03  1.07273335e+02  4.20529961e+01 ... -1.24642162e+00\n",
      "  -6.49072096e-01  1.07213150e+00]\n",
      " [ 1.33900000e+03  1.12703974e+02  4.78657173e+01 ...  4.70730658e-02\n",
      "  -2.51965944e-01 -3.59163342e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "potB1vN5fxqI",
    "outputId": "13d88615-b3ca-46a0-e479-18949ee36f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n",
      "752\n",
      "587\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "\n",
    "count1=0\n",
    "count0=0\n",
    "\n",
    "for n in y_train:\n",
    "  if n==1:\n",
    "    count1=count1+1\n",
    "  else:\n",
    "    count0=count0+1\n",
    "\n",
    "print(count1)\n",
    "print(count0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un6aXeGQ-Bd2"
   },
   "source": [
    "# Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lIg2QwfU-GhZ",
    "outputId": "be750c8a-53df-4987-97e1-a961988e9950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8193\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9447\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9627\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9686\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9746\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9537\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9731\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9806\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9903\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9866\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9888\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9940\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9955\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9948\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9612\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9873\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9918\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9963\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9970\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9910\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9948\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9948\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9910\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9940\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9963\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9970\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9940\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9963\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9970\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9970\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9955\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9985\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9970\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9963\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9978\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9978\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9895\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9858\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9821\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9910\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9903\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9940\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9933\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9978\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9963\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9963\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9970\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9985\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9963\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9978\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9948\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9963\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9940\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9828\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9918\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9955\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9963\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9970\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9978\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9955\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9970\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9940\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9948\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9970\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9970\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9963\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9978 ETA: 0s - loss: 0.0058 - accuracy: 0.99\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9978\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9978\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9985\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9985\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9985\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9955\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9985\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9978\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9978\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9985\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9978\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9955\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9970\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9970\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9955\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9948\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9686\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0b546b7d90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "#class_weight={1:1, 0:5}\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=12, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, batch_size = 16, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31FwZFBf4Vmk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "ude1J0E47SKN",
    "outputId": "225fcaf7-9f23-4542-c23e-eaa4034fab66"
   },
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#classifier = XGBClassifier()\n",
    "#classifier.fit(X_train, y_train)\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04CKLTr894tv"
   },
   "source": [
    "#Predicting Validation set results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "SoHWkVPH1s_O",
    "outputId": "f9bd9c68-135a-4b5a-a228-2b29ed89d728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "501\n",
      "156\n",
      "[[ 1.00000000e+00  1.04826834e+02  4.12479709e+01 ... -1.66588102e+00\n",
      "   1.54536971e+00 -4.79476709e-01]\n",
      " [ 2.00000000e+00  1.09004854e+02  3.35838110e+01 ... -2.63355575e+00\n",
      "  -8.46839943e-01  1.31392004e+00]\n",
      " [ 3.00000000e+00  1.08294125e+02  4.06620371e+01 ... -9.06676587e-01\n",
      "   8.10714198e-01 -6.42887530e-01]\n",
      " ...\n",
      " [ 4.99000000e+02  1.11322786e+02  4.53693776e+01 ...  5.12968365e-01\n",
      "   6.96611427e-01  9.22126793e-01]\n",
      " [ 5.00000000e+02  1.10193302e+02  4.50443247e+01 ... -5.12303733e-01\n",
      "  -4.85042104e-01 -1.00620116e+00]\n",
      " [ 5.01000000e+02  1.11655703e+02  4.56392055e+01 ... -7.23516434e-01\n",
      "  -2.02709548e+00  1.35407658e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('X_testData_column_modified_PCA_CAP.csv')\n",
    "#test_data = pd.read_csv('X_testData_1_modified.csv')\n",
    "\n",
    "X_test=test_data.iloc[:,:].values\n",
    "\n",
    "\n",
    "print(type(X_test))\n",
    "print(len(X_test))\n",
    "print(len(X_test[0]))\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3L4wXUSM987y",
    "outputId": "38c72dad-1283-4884-e9d2-9f8ab6ed2e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        ]\n",
      " [0.99890125]\n",
      " [0.9997807 ]\n",
      " [0.9985454 ]\n",
      " [0.9996532 ]\n",
      " [0.99976665]\n",
      " [0.9954814 ]\n",
      " [1.        ]\n",
      " [0.99979943]\n",
      " [1.        ]\n",
      " [0.99999976]\n",
      " [0.9977088 ]\n",
      " [0.99847806]\n",
      " [0.9995085 ]\n",
      " [0.99999964]\n",
      " [0.9959375 ]\n",
      " [1.        ]\n",
      " [0.9972013 ]\n",
      " [0.99999887]\n",
      " [1.        ]\n",
      " [0.9999997 ]\n",
      " [0.9985157 ]\n",
      " [1.        ]\n",
      " [0.9998183 ]\n",
      " [0.9999398 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999714]\n",
      " [0.9697374 ]\n",
      " [0.9999905 ]\n",
      " [0.9999999 ]\n",
      " [0.9997107 ]\n",
      " [0.9926185 ]\n",
      " [1.        ]\n",
      " [0.5144373 ]\n",
      " [0.99973285]\n",
      " [0.9939601 ]\n",
      " [1.        ]\n",
      " [0.99922246]\n",
      " [0.9996094 ]\n",
      " [0.99996334]\n",
      " [0.9990462 ]\n",
      " [0.9999813 ]\n",
      " [1.        ]\n",
      " [0.9995167 ]\n",
      " [0.9980295 ]\n",
      " [0.9999677 ]\n",
      " [0.9979174 ]\n",
      " [0.99785393]\n",
      " [0.9982228 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999435 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99617743]\n",
      " [1.        ]\n",
      " [0.9999784 ]\n",
      " [0.9999027 ]\n",
      " [0.99999857]\n",
      " [0.9999863 ]\n",
      " [0.9996424 ]\n",
      " [1.        ]\n",
      " [0.99999493]\n",
      " [1.        ]\n",
      " [0.9994267 ]\n",
      " [0.9995736 ]\n",
      " [0.9999682 ]\n",
      " [0.99531686]\n",
      " [0.98844546]\n",
      " [0.9999853 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999943 ]\n",
      " [0.99894965]\n",
      " [0.9999901 ]\n",
      " [0.99994946]\n",
      " [0.9982442 ]\n",
      " [1.        ]\n",
      " [0.9999994 ]\n",
      " [1.        ]\n",
      " [0.9999938 ]\n",
      " [1.        ]\n",
      " [0.99965024]\n",
      " [1.        ]\n",
      " [0.9996762 ]\n",
      " [0.99981385]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9949149 ]\n",
      " [0.9996519 ]\n",
      " [0.9996191 ]\n",
      " [0.998057  ]\n",
      " [0.9997183 ]\n",
      " [0.97636837]\n",
      " [0.99999344]\n",
      " [0.99947625]\n",
      " [1.        ]\n",
      " [0.99999756]\n",
      " [0.996488  ]\n",
      " [1.        ]\n",
      " [0.97430813]\n",
      " [0.9999899 ]\n",
      " [0.98075056]\n",
      " [0.99998504]\n",
      " [0.99398553]\n",
      " [0.99997574]\n",
      " [0.99944717]\n",
      " [1.        ]\n",
      " [0.99999815]\n",
      " [0.9999988 ]\n",
      " [1.        ]\n",
      " [0.9819311 ]\n",
      " [0.98185074]\n",
      " [0.999995  ]\n",
      " [0.97375995]\n",
      " [0.999987  ]\n",
      " [0.99992466]\n",
      " [0.9998503 ]\n",
      " [0.25402072]\n",
      " [1.        ]\n",
      " [0.999554  ]\n",
      " [0.9900447 ]\n",
      " [0.9999962 ]\n",
      " [0.99717295]\n",
      " [0.75466764]\n",
      " [0.99999166]\n",
      " [0.99940753]\n",
      " [0.5507884 ]\n",
      " [0.99761903]\n",
      " [0.99999654]\n",
      " [0.9992804 ]\n",
      " [0.9994389 ]\n",
      " [0.9979147 ]\n",
      " [0.997983  ]\n",
      " [1.        ]\n",
      " [0.9998636 ]\n",
      " [0.9999992 ]\n",
      " [0.9994421 ]\n",
      " [0.9999664 ]\n",
      " [1.        ]\n",
      " [0.998429  ]\n",
      " [0.9999993 ]\n",
      " [0.99999964]\n",
      " [0.9999552 ]\n",
      " [0.99999976]\n",
      " [1.        ]\n",
      " [0.9999989 ]\n",
      " [0.9999912 ]\n",
      " [1.        ]\n",
      " [0.9999869 ]\n",
      " [1.        ]\n",
      " [0.99999905]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99997884]\n",
      " [0.9998852 ]\n",
      " [1.        ]\n",
      " [0.9999651 ]\n",
      " [0.99979997]\n",
      " [0.99998623]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9995837 ]\n",
      " [0.9999986 ]\n",
      " [0.9999994 ]\n",
      " [0.99999976]\n",
      " [0.9997692 ]\n",
      " [0.9975145 ]\n",
      " [0.9999994 ]\n",
      " [1.        ]\n",
      " [0.999987  ]\n",
      " [0.9480432 ]\n",
      " [0.9981859 ]\n",
      " [0.99990773]\n",
      " [0.4572273 ]\n",
      " [0.9999995 ]\n",
      " [1.        ]\n",
      " [0.9999984 ]\n",
      " [0.9999995 ]\n",
      " [0.99999046]\n",
      " [0.99999475]\n",
      " [0.9996984 ]\n",
      " [0.999817  ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999997 ]\n",
      " [0.9997754 ]\n",
      " [0.99999255]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.98714036]\n",
      " [0.9999816 ]\n",
      " [0.9999938 ]\n",
      " [0.99999547]\n",
      " [0.9999981 ]\n",
      " [0.9999938 ]\n",
      " [0.99994695]\n",
      " [0.99989927]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.64425075]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998903]\n",
      " [0.4067908 ]\n",
      " [1.        ]\n",
      " [0.99999094]\n",
      " [0.99999535]\n",
      " [1.        ]\n",
      " [0.99215555]\n",
      " [0.99999785]\n",
      " [0.99330366]\n",
      " [0.99999845]\n",
      " [0.9985907 ]\n",
      " [1.        ]\n",
      " [0.9993391 ]\n",
      " [0.99998635]\n",
      " [0.9999347 ]\n",
      " [0.99999845]\n",
      " [0.94648355]\n",
      " [0.99992293]\n",
      " [0.9998835 ]\n",
      " [0.99972475]\n",
      " [0.9884374 ]\n",
      " [0.9996575 ]\n",
      " [0.9994739 ]\n",
      " [0.9993034 ]\n",
      " [1.        ]\n",
      " [0.99999756]\n",
      " [0.9999968 ]\n",
      " [0.9997177 ]\n",
      " [0.99997765]\n",
      " [0.9789058 ]\n",
      " [1.        ]\n",
      " [0.99982774]\n",
      " [0.9998992 ]\n",
      " [1.        ]\n",
      " [0.9999958 ]\n",
      " [0.9994632 ]\n",
      " [0.9996023 ]\n",
      " [0.9990293 ]\n",
      " [0.9999994 ]\n",
      " [1.        ]\n",
      " [0.9999962 ]\n",
      " [0.99999976]\n",
      " [1.        ]\n",
      " [0.9996235 ]\n",
      " [0.99995756]\n",
      " [1.        ]\n",
      " [0.9999989 ]\n",
      " [0.9999993 ]\n",
      " [1.        ]\n",
      " [0.99453515]\n",
      " [0.99753577]\n",
      " [1.        ]\n",
      " [0.9999758 ]\n",
      " [0.99999565]\n",
      " [0.9999981 ]\n",
      " [0.9999583 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9979263 ]\n",
      " [0.9999125 ]\n",
      " [0.99999976]\n",
      " [0.62107277]\n",
      " [0.9999924 ]\n",
      " [0.999995  ]\n",
      " [0.9999997 ]\n",
      " [0.9993076 ]\n",
      " [1.        ]\n",
      " [0.99988556]\n",
      " [0.999791  ]\n",
      " [1.        ]\n",
      " [0.9784106 ]\n",
      " [0.99999535]\n",
      " [1.        ]\n",
      " [0.8953595 ]\n",
      " [0.9999999 ]\n",
      " [0.9999474 ]\n",
      " [0.9997339 ]\n",
      " [0.81606007]\n",
      " [1.        ]\n",
      " [0.9999913 ]\n",
      " [1.        ]\n",
      " [0.99974704]\n",
      " [0.99999756]\n",
      " [0.9997424 ]\n",
      " [0.9998499 ]\n",
      " [0.99998057]\n",
      " [0.9284804 ]\n",
      " [0.9999998 ]\n",
      " [0.9995753 ]\n",
      " [0.9995471 ]\n",
      " [0.9999973 ]\n",
      " [1.        ]\n",
      " [0.99946344]\n",
      " [0.9998866 ]\n",
      " [0.9999892 ]\n",
      " [0.9825481 ]\n",
      " [0.96335244]\n",
      " [1.        ]\n",
      " [0.9999386 ]\n",
      " [0.99981517]\n",
      " [0.99999905]\n",
      " [0.9999745 ]\n",
      " [0.9999994 ]\n",
      " [0.9944749 ]\n",
      " [0.999993  ]\n",
      " [0.9999996 ]\n",
      " [0.9999818 ]\n",
      " [0.9999763 ]\n",
      " [0.99999976]\n",
      " [0.99996597]\n",
      " [0.99999547]\n",
      " [0.999998  ]\n",
      " [1.        ]\n",
      " [0.94869995]\n",
      " [0.9986601 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999992 ]\n",
      " [0.99999905]\n",
      " [0.99965763]\n",
      " [0.9997531 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9495166 ]\n",
      " [1.        ]\n",
      " [0.9999919 ]\n",
      " [0.98736036]\n",
      " [0.99999344]\n",
      " [0.99994946]\n",
      " [0.9998798 ]\n",
      " [1.        ]\n",
      " [0.9999996 ]\n",
      " [0.9999996 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999964]\n",
      " [0.9126233 ]\n",
      " [0.98010194]\n",
      " [0.9798292 ]\n",
      " [1.        ]\n",
      " [0.9999925 ]\n",
      " [0.9999236 ]\n",
      " [0.9998808 ]\n",
      " [0.99992824]\n",
      " [0.99989295]\n",
      " [0.9999993 ]\n",
      " [0.99922276]\n",
      " [0.99998987]\n",
      " [0.99965566]\n",
      " [0.9998196 ]\n",
      " [0.99981743]\n",
      " [0.999992  ]\n",
      " [0.9998934 ]\n",
      " [0.9395436 ]\n",
      " [0.9396405 ]\n",
      " [0.72404146]\n",
      " [0.99825513]\n",
      " [0.9988802 ]\n",
      " [0.9999992 ]\n",
      " [0.9999809 ]\n",
      " [0.9999577 ]\n",
      " [0.9415139 ]\n",
      " [0.9985077 ]\n",
      " [0.94219047]\n",
      " [0.942526  ]\n",
      " [0.9999212 ]\n",
      " [0.9431915 ]\n",
      " [0.9999962 ]\n",
      " [0.9993186 ]\n",
      " [0.97733355]\n",
      " [0.9996829 ]\n",
      " [0.7414823 ]\n",
      " [0.9954858 ]\n",
      " [0.9744743 ]\n",
      " [0.99992603]\n",
      " [0.9463042 ]\n",
      " [0.9712195 ]\n",
      " [0.99760437]\n",
      " [0.99745417]\n",
      " [0.9999821 ]\n",
      " [1.        ]\n",
      " [0.999676  ]\n",
      " [0.99922264]\n",
      " [0.97675353]\n",
      " [0.9487783 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9517536 ]\n",
      " [0.98724985]\n",
      " [0.99961877]\n",
      " [0.95490503]\n",
      " [1.        ]\n",
      " [0.99999   ]\n",
      " [0.9999949 ]\n",
      " [0.9998423 ]\n",
      " [0.9999912 ]\n",
      " [0.9997069 ]\n",
      " [0.9999969 ]\n",
      " [0.9999995 ]\n",
      " [0.9997708 ]\n",
      " [0.99999803]\n",
      " [0.9987798 ]\n",
      " [0.0280118 ]\n",
      " [0.9999958 ]\n",
      " [0.999795  ]\n",
      " [0.99999976]\n",
      " [0.9999995 ]\n",
      " [0.9999988 ]\n",
      " [1.        ]\n",
      " [0.99999547]\n",
      " [0.7803041 ]\n",
      " [0.9921313 ]\n",
      " [0.9999523 ]\n",
      " [1.        ]\n",
      " [0.9985129 ]\n",
      " [0.9999987 ]\n",
      " [0.9779633 ]\n",
      " [0.99894285]\n",
      " [0.97924083]\n",
      " [0.9999967 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999995 ]\n",
      " [0.999984  ]\n",
      " [0.9999844 ]\n",
      " [0.9394014 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9981723 ]\n",
      " [0.9855777 ]\n",
      " [0.98618007]\n",
      " [0.99988997]\n",
      " [1.        ]\n",
      " [0.9999982 ]\n",
      " [0.9883516 ]\n",
      " [0.9888469 ]\n",
      " [0.903738  ]\n",
      " [0.99999845]\n",
      " [0.9902348 ]\n",
      " [1.        ]\n",
      " [0.95552015]\n",
      " [0.7855731 ]\n",
      " [0.9999625 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.87481904]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999995 ]\n",
      " [0.9999988 ]\n",
      " [1.        ]\n",
      " [0.99952316]\n",
      " [0.990114  ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999101 ]\n",
      " [1.        ]\n",
      " [0.99999857]\n",
      " [0.9999994 ]\n",
      " [0.99283504]\n",
      " [1.        ]\n",
      " [0.981266  ]\n",
      " [0.99918413]\n",
      " [1.        ]\n",
      " [0.9797794 ]\n",
      " [1.        ]\n",
      " [0.9999983 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9976405 ]\n",
      " [0.99999124]\n",
      " [0.999794  ]\n",
      " [0.99312365]\n",
      " [1.        ]\n",
      " [0.99509275]\n",
      " [0.999994  ]\n",
      " [0.9999877 ]\n",
      " [0.9954503 ]\n",
      " [1.        ]\n",
      " [0.9999993 ]\n",
      " [0.9998388 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999607]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#y_pred = classifier.predict_proba(X_test)\n",
    "#y_pred = classifier.predict(X_test)\n",
    "y_pred = ann.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(type(y_pred))\n",
    "#y_pred = (y_pred > 0.5)\n",
    "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_validation.reshape(len(y_validation),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "h-VlhXT5075B",
    "outputId": "b474822e-4b1a-416d-87a1-e2d2f0751941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "QgwFIpIhCPlq",
    "outputId": "a132ba05-e7f9-4522-a0e4-5dd4f9f02429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ID', 'CAP'], [1, 1.0], [2, 0.99890125], [3, 0.9997807], [4, 0.9985454], [5, 0.9996532], [6, 0.99976665], [7, 0.9954814], [8, 1.0], [9, 0.99979943], [10, 1.0], [11, 0.99999976], [12, 0.9977088], [13, 0.99847806], [14, 0.9995085], [15, 0.99999964], [16, 0.9959375], [17, 1.0], [18, 0.9972013], [19, 0.99999887], [20, 1.0], [21, 0.9999997], [22, 0.9985157], [23, 1.0], [24, 0.9998183], [25, 0.9999398], [26, 1.0], [27, 1.0], [28, 0.99999714], [29, 0.9697374], [30, 0.9999905], [31, 0.9999999], [32, 0.9997107], [33, 0.9926185], [34, 1.0], [35, 0.5144373], [36, 0.99973285], [37, 0.9939601], [38, 1.0], [39, 0.99922246], [40, 0.9996094], [41, 0.99996334], [42, 0.9990462], [43, 0.9999813], [44, 1.0], [45, 0.9995167], [46, 0.9980295], [47, 0.9999677], [48, 0.9979174], [49, 0.99785393], [50, 0.9982228], [51, 1.0], [52, 1.0], [53, 0.9999435], [54, 1.0], [55, 1.0], [56, 0.99617743], [57, 1.0], [58, 0.9999784], [59, 0.9999027], [60, 0.99999857], [61, 0.9999863], [62, 0.9996424], [63, 1.0], [64, 0.99999493], [65, 1.0], [66, 0.9994267], [67, 0.9995736], [68, 0.9999682], [69, 0.99531686], [70, 0.98844546], [71, 0.9999853], [72, 1.0], [73, 1.0], [74, 1.0], [75, 0.9999943], [76, 0.99894965], [77, 0.9999901], [78, 0.99994946], [79, 0.9982442], [80, 1.0], [81, 0.9999994], [82, 1.0], [83, 0.9999938], [84, 1.0], [85, 0.99965024], [86, 1.0], [87, 0.9996762], [88, 0.99981385], [89, 1.0], [90, 1.0], [91, 0.9949149], [92, 0.9996519], [93, 0.9996191], [94, 0.998057], [95, 0.9997183], [96, 0.97636837], [97, 0.99999344], [98, 0.99947625], [99, 1.0], [100, 0.99999756], [101, 0.996488], [102, 1.0], [103, 0.97430813], [104, 0.9999899], [105, 0.98075056], [106, 0.99998504], [107, 0.99398553], [108, 0.99997574], [109, 0.99944717], [110, 1.0], [111, 0.99999815], [112, 0.9999988], [113, 1.0], [114, 0.9819311], [115, 0.98185074], [116, 0.999995], [117, 0.97375995], [118, 0.999987], [119, 0.99992466], [120, 0.9998503], [121, 0.25402072], [122, 1.0], [123, 0.999554], [124, 0.9900447], [125, 0.9999962], [126, 0.99717295], [127, 0.75466764], [128, 0.99999166], [129, 0.99940753], [130, 0.5507884], [131, 0.99761903], [132, 0.99999654], [133, 0.9992804], [134, 0.9994389], [135, 0.9979147], [136, 0.997983], [137, 1.0], [138, 0.9998636], [139, 0.9999992], [140, 0.9994421], [141, 0.9999664], [142, 1.0], [143, 0.998429], [144, 0.9999993], [145, 0.99999964], [146, 0.9999552], [147, 0.99999976], [148, 1.0], [149, 0.9999989], [150, 0.9999912], [151, 1.0], [152, 0.9999869], [153, 1.0], [154, 0.99999905], [155, 1.0], [156, 1.0], [157, 1.0], [158, 0.99997884], [159, 0.9998852], [160, 1.0], [161, 0.9999651], [162, 0.99979997], [163, 0.99998623], [164, 1.0], [165, 1.0], [166, 0.9995837], [167, 0.9999986], [168, 0.9999994], [169, 0.99999976], [170, 0.9997692], [171, 0.9975145], [172, 0.9999994], [173, 1.0], [174, 0.999987], [175, 0.9480432], [176, 0.9981859], [177, 0.99990773], [178, 0.4572273], [179, 0.9999995], [180, 1.0], [181, 0.9999984], [182, 0.9999995], [183, 0.99999046], [184, 0.99999475], [185, 0.9996984], [186, 0.999817], [187, 1.0], [188, 1.0], [189, 1.0], [190, 0.9999997], [191, 0.9997754], [192, 0.99999255], [193, 1.0], [194, 1.0], [195, 1.0], [196, 0.98714036], [197, 0.9999816], [198, 0.9999938], [200, 0.99999547], [202, 0.9999981], [204, 0.9999938], [206, 0.99994695], [208, 0.99989927], [212, 1.0], [213, 1.0], [215, 1.0], [216, 1.0], [217, 0.64425075], [218, 1.0], [219, 1.0], [220, 0.99998903], [221, 0.4067908], [222, 1.0], [224, 0.99999094], [227, 0.99999535], [228, 1.0], [231, 0.99215555], [232, 0.99999785], [234, 0.99330366], [235, 0.99999845], [236, 0.9985907], [238, 1.0], [239, 0.9993391], [240, 0.99998635], [242, 0.9999347], [243, 0.99999845], [244, 0.94648355], [245, 0.99992293], [247, 0.9998835], [251, 0.99972475], [256, 0.9884374], [257, 0.9996575], [258, 0.9994739], [259, 0.9993034], [262, 1.0], [263, 0.99999756], [264, 0.9999968], [266, 0.9997177], [267, 0.99997765], [270, 0.9789058], [271, 1.0], [272, 0.99982774], [278, 0.9998992], [279, 1.0], [280, 0.9999958], [281, 0.9994632], [287, 0.9996023], [289, 0.9990293], [290, 0.9999994], [296, 1.0], [302, 0.9999962], [307, 0.99999976], [316, 1.0], [319, 0.9996235], [320, 0.99995756], [325, 1.0], [333, 0.9999989], [345, 0.9999993], [352, 1.0], [356, 0.99453515], [363, 0.99753577], [380, 1.0], [381, 0.9999758], [388, 0.99999565], [392, 0.9999981], [398, 0.9999583], [413, 1.0], [422, 1.0], [431, 0.9979263], [455, 0.9999125], [467, 0.99999976], [483, 0.62107277], [485, 0.9999924], [488, 0.999995], [498, 0.9999997], [503, 0.9993076], [510, 1.0], [524, 0.99988556], [543, 0.999791], [549, 1.0], [554, 0.9784106], [559, 0.99999535], [565, 1.0], [567, 0.8953595], [576, 0.9999999], [579, 0.9999474], [588, 0.9997339], [598, 0.81606007], [599, 1.0], [601, 0.9999913], [603, 1.0], [628, 0.99974704], [631, 0.99999756], [632, 0.9997424], [633, 0.9998499], [634, 0.99998057], [635, 0.9284804], [636, 0.9999998], [637, 0.9995753], [638, 0.9995471], [639, 0.9999973], [640, 1.0], [641, 0.99946344], [642, 0.9998866], [643, 0.9999892], [644, 0.9825481], [645, 0.96335244], [646, 1.0], [647, 0.9999386], [648, 0.99981517], [649, 0.99999905], [650, 0.9999745], [651, 0.9999994], [652, 0.9944749], [653, 0.999993], [654, 0.9999996], [655, 0.9999818], [656, 0.9999763], [657, 0.99999976], [658, 0.99996597], [659, 0.99999547], [660, 0.999998], [661, 1.0], [662, 0.94869995], [663, 0.9986601], [664, 1.0], [665, 1.0], [666, 0.9999992], [667, 0.99999905], [668, 0.99965763], [669, 0.9997531], [670, 1.0], [671, 1.0], [672, 1.0], [673, 0.9495166], [674, 1.0], [675, 0.9999919], [676, 0.98736036], [677, 0.99999344], [678, 0.99994946], [679, 0.9998798], [680, 1.0], [681, 0.9999996], [682, 0.9999996], [683, 1.0], [684, 1.0], [685, 0.99999964], [686, 0.9126233], [687, 0.98010194], [688, 0.9798292], [689, 1.0], [692, 0.9999925], [693, 0.9999236], [694, 0.9998808], [695, 0.99992824], [696, 0.99989295], [697, 0.9999993], [698, 0.99922276], [699, 0.99998987], [700, 0.99965566], [701, 0.9998196], [702, 0.99981743], [703, 0.999992], [704, 0.9998934], [705, 0.9395436], [706, 0.9396405], [707, 0.72404146], [708, 0.99825513], [709, 0.9988802], [710, 0.9999992], [711, 0.9999809], [712, 0.9999577], [713, 0.9415139], [714, 0.9985077], [715, 0.94219047], [716, 0.942526], [717, 0.9999212], [718, 0.9431915], [719, 0.9999962], [720, 0.9993186], [721, 0.97733355], [722, 0.9996829], [723, 0.7414823], [724, 0.9954858], [725, 0.9744743], [726, 0.99992603], [727, 0.9463042], [728, 0.9712195], [729, 0.99760437], [730, 0.99745417], [731, 0.9999821], [732, 1.0], [733, 0.999676], [734, 0.99922264], [735, 0.97675353], [736, 0.9487783], [737, 1.0], [738, 1.0], [739, 1.0], [740, 0.9517536], [741, 0.98724985], [742, 0.99961877], [743, 0.95490503], [744, 1.0], [745, 0.99999], [746, 0.9999949], [747, 0.9998423], [748, 0.9999912], [749, 0.9997069], [750, 0.9999969], [751, 0.9999995], [752, 0.9997708], [753, 0.99999803], [754, 0.9987798], [755, 0.028011799], [756, 0.9999958], [757, 0.999795], [758, 0.99999976], [759, 0.9999995], [760, 0.9999988], [761, 1.0], [762, 0.99999547], [763, 0.7803041], [764, 0.9921313], [765, 0.9999523], [766, 1.0], [767, 0.9985129], [768, 0.9999987], [769, 0.9779633], [770, 0.99894285], [771, 0.97924083], [772, 0.9999967], [773, 1.0], [774, 1.0], [775, 0.9999995], [776, 0.999984], [777, 0.9999844], [778, 0.9394014], [779, 1.0], [780, 1.0], [781, 1.0], [782, 0.9981723], [783, 0.9855777], [784, 0.98618007], [785, 0.99988997], [786, 1.0], [787, 0.9999982], [788, 0.9883516], [789, 0.9888469], [790, 0.903738], [791, 0.99999845], [792, 0.9902348], [805, 1.0], [809, 0.95552015], [816, 0.7855731], [826, 0.9999625], [841, 1.0], [847, 1.0], [893, 1.0], [951, 0.87481904], [952, 1.0], [953, 1.0], [954, 0.9999995], [955, 0.9999988], [956, 1.0], [957, 0.99952316], [958, 0.990114], [959, 1.0], [960, 1.0], [961, 0.9999101], [962, 1.0], [963, 0.99999857], [964, 0.9999994], [965, 0.99283504], [966, 1.0], [967, 0.981266], [968, 0.99918413], [969, 1.0], [970, 0.9797794], [971, 1.0], [972, 0.9999983], [973, 1.0], [974, 1.0], [975, 1.0], [976, 0.9976405], [977, 0.99999124], [978, 0.999794], [979, 0.99312365], [980, 1.0], [981, 0.99509275], [982, 0.999994], [983, 0.9999877], [984, 0.9954503], [985, 1.0], [986, 0.9999993], [987, 0.9998388], [988, 1.0], [989, 1.0], [990, 1.0], [991, 1.0], [992, 0.99999607]]\n"
     ]
    }
   ],
   "source": [
    "submission_data = pd.read_csv('Y_testData_1_nolabels_CAP.csv')\n",
    "\n",
    "ids=submission_data.iloc[:,:1].values\n",
    "result=list()\n",
    "k=0\n",
    "#print(ids)\n",
    "#print(y_pred[0])\n",
    "for i in ids:\n",
    "  #result.append([ i[0], y_pred[i[0]-1][0] ])\n",
    "  #result.append([ i[0], y_pred[i[0]-1][0] ])\n",
    "  result.append([ i[0], y_pred[k][0] ])\n",
    "  #result.append([ i[0], y_pred[k][1] ])\n",
    "  k=k+1\n",
    "  #print(y_pred[i[0]-1][0])\n",
    "  #print('.')\n",
    "\n",
    "result.insert(0, ['ID','CAP'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Q1zP-sxYFP46"
   },
   "outputs": [],
   "source": [
    "file = open('CAP_result.csv', 'w+', newline ='') \n",
    "  \n",
    "# writing the data into the file \n",
    "with file:     \n",
    "    write = csv.writer(file) \n",
    "    write.writerows(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa-vi0QM-LC9"
   },
   "source": [
    "# Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cw5t7mVa-Phl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYyn2oDE3JmY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCCFSasG3XYt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE37sSMdzp-n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PCA-NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
